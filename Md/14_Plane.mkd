## Linear fields on the plane
\label{sect:plane}

### General solution

We consider the vector field defined in $\mathbb{R}^2\rightarrow \mathbb{R}^2$, with $\vec{x} \in \mathbb{R}^2$. 

Before we start anything, we will have to define the notion of invariant set. 

\bd{Invariant set}
A set $S$ is said to be invariant _under the vector field_ $\dot{\vec{x}} = \vec{f}(\vec{x},t)$ if for any $\vec{x}_0\in S$, its trajectory $\vec{x}(t,t_0,x_0) \in S$ (see def. of trajectory in sect.  \ref{def:trajectory})
\ed

Technically, much of what follows here actually applies to _invariant manifolds_, which are invariant sets that that are locally differentiable (you can describe them locally as a vector space. We will not insist on this difference here. Note that, by definition, an _orbit_ is an invariant set, but an invariant set is not necessarily an orbit.

Now, this chapter is specifically dedicated to linear, autonomous dynamical systems. In other words, they can be written in matrix notation:

$$ \dot{\vec{x}}  = A \vec{x}.$$

The flow\index{flow} associated with such linear fields are linear diffeomorphisms\index{diffeomorphism} (the space is deformed continuously and linearly). 

The Jordan canonical form theorem tells [^Jordan] us that, if $A$ is a real two by two matrix, there is a non-singular real matrix $T$ such that $A=TJT^{-1}$, and $T$ is made of two  columns with vectors $\vec{u}$ and $\vec{v}$.  Depending on the eigenvalue and eigenvectors of $A$, $J$ will be of one of three forms:

- _Case A_: Two independent eigenvectors ($\vec{u}$ and $\vec{v}$), real eigenvalues : $J = \begin{pmatrix} \lambda_1 & 0 \\ 0 & \lambda_2 \end{pmatrix}$;
- _Case B_: Complex eigenvalues $\lambda_r \pm i \omega$: $J = \begin{pmatrix} \lambda_r & \omega \\ -\omega & \lambda_r \end{pmatrix}$;
- _Case C_: A single independent eigenvector ($\vec{u}$), with one single real eigenvalue $J = \begin{pmatrix} \lambda & 1 \\ 0 & \lambda \end{pmatrix}$. 


[^Jordan]:More on this \ref{sect:Jordan}. The relevant intuition is that the original space is deformed and rotated so that the vectors $\vec{u}$ and $\vec{v}$ are aligned on the $x-$ and $y-$axes. We can see this as follows. The original equation $\dot{ \vec{x}} = A\vec{x}$ can be rewritten as $T^{-1}\dot{\vec{x}} =  JT^{-1}\vec{x}$. So this is an linear equation with operator $J$ for the vector $T^{-1}\dot{\vec{x}}$. When $\vec{x}$ is $\vec{u}$, then $T^{-1}\vec{x} = (1 Â  0)^{\mathsf{T}}$ (verify this by mulitplying both sides by $T$ and replace $\vec{x}$ by $\vec{u}$; the index $\mathsf{T}$ on the right-hand-side is there to denote a column matrix). 

Geometrically, $T$ is the composition of a rotation, dilation and reflection around the origin.
Vectors $\vec{u}$ and $\vec{v}$ are not necessarily orthogonal. We only have this guarantee when the matrix $A$ is symmetric. 

### Hyperbolicity

\bd{Hyperbolic fixed point.} A fixed point is hyperbolic if all the eigenvalues of $\Dif f(x_f)$ have either a strictly positive or a strictly negative real part.
\ed

We will be able to _prove_ that a fixed point with all _negative_ eigenvalues (said to be linearly stable) is asymptotically stable. But we leave it for later. At this point, we already know enough to understand the idea of sink and source:

1. A hyperbolic fixed point is called a _sink_ if all eigenvalues of the Lyapunov spectrum have negative real parts. 
2. A hyperbolic fixed point is called a _source_ if all eigenvalues of the Lyapunov spectrum have positive real parts.
3. A hyperbolic fixed point is called a _saddle_ if some but not all eigenvalues of the Lyapunov spectrum have positive real parts
4. A non-hyperbolic fixed point with purely imaginary eigenvalues, and non-zero is a _center_.



### Case A: Real eigenvalues and linearly independent eigenvectors : invariant manifolds and linear transient growth


The general solution to the ordinary differential equation is $$\vec{x}(t) = C_1 e^{\lambda_1 t} \vec{u} +  C_2 e^{\lambda_2 t} \vec{v},$$ where $\vec u$ and $\vec v$ are the eigenvectors, and $\lambda_1$ and $\lambda_2$ the respective eigenvalues. 

The fixed point $(0,0)$ is asymptotically attracting if it is a hyperbolic fixed point with $\lambda_{1,2} < 0$. Furthermore, for an initial condition along the eigenvector $\vec{u}$, that is, $\vec{x}_0 = \alpha \vec{u}$, the particular solution is $\vec{x} = \alpha e^{\lambda_1 t} \vec{u}$. In other words, in the particular case of an initial condition along an eigenvector, the orbit is a line. 

In other words, the lines defined respectively  by $\alpha \vec{u}$ and $\beta \vec{v}$, $\alpha,\beta\in\mathbb{R}$ have a special property: if you are on the line. They are invariant sets and given that we are in a 2-D domain, these lines effectively partition the state space. If a trajectory is born on one side of the set, it remains there. 

At this point we can already have some intuitive grasp on what is going on.
Some of these lines are associated with an exponentially growing solution (the associated  $\lambda$ is positive): This is an _unstable_ manifold. Some, to the contrary, bring you asymptotically to the fixed point $(0,0)$. They are _stable_. Whether they are stable or unstable depends on the eigenvalue. 

\efigure{plane_convergence}

<!-- \includegraphics[page=15, angle=90, scale=0.7, trim={1cm 0 0 0cm}, clip]{lphys2114-figures} -->

However, these are particular cases: even when both eigenvalues are real, the orbit is _not_ a line. Consider the case of a hyperbolic sink ($\lambda_1,\lambda_2<0$). One can view that $-\lambda_1$ and $-\lambda_2$ act as the inverse of attracting time scales. For example,  |$\lambda_1| \gg |\lambda_2|$ imply that the trajectory will be quickly attracted towards the $u-$component of the trajectory will vanish quickly, so that it will be quickly attracted towards the manifold associated with the second eigenvalue. The $\beta \vec{v}$ will act as a _slow manifold_. 


A further counter-intuitive behaviour may occur in the case $\vec{u}$ and $\vec{v}$ are non-orthogonal. As the $u$-component quickly vanishes (in this example), the _norm_ of the vector $$\vec{x}(t) = C_1 e^{\lambda_1 t} \vec{u} +  C_2 e^{\lambda_2 t} \vec{v},$$ may display a _transient growth_. This phenomenon, called _non-normal growth_ is common in fluid dynamics and has been suggested to be important in the early phases of the dynamics of the ocean-atmosphere phenomenon El-Nino [^1].

\efigure{nonnormal}

[^1]:Von der Heydt and Dijkstra, \url{https://dspace.library.uu.nl/bitstream/handle/1874/314407/naw5_2013_14_3_195.pdf?sequence=1}

### Case B: Complex eigenvalues : spiral and center 

The eigenvectors associated with the matrix form $B$ are $(1, i)$ and $(1, -i)$ $i=\sqrt{-1}$. 
Thus, the general solution reads (with $x$, $y$ the components of the solution):

\begin{displaymath}
\vectort{x}{y} = A e^{(\lambda_r + i\omega) t}\vectort{1}{i} + 
                 B e^{(\lambda_r - i\omega)t}\vectort{1}{-i} 
\end{displaymath}

Requiring $x$ and $y$ to be real imposes $2A=2B=C=C_0e^{i\phi_0}$, where $C\in\mathbb{C}$ and $C_0$, $\phi_0\in \mathbb{R}$. 

We then observe that $x+iy$ behaves as a complex phasor $\mathbf{q}$, with amplitude growing or shrinking exponentially depending on the sign of $\lambda_r$, and rotating clockwise with $\omega$:

\begin{displaymath}
\mathbf{q} = x+iy = C e^{\lambda_r} e^{ - i\omega t}
\end{displaymath}


\efigure{spiral_inwards}

Two more examples:

The frictionless, linear harmonic oscillator is defined by (after a suitable choice of length unit):

$$\vectort{\dot q}{\dot p} = \begin{pmatrix}  0 & 1 \\ -\omega^2 & 0 \end{pmatrix} \vectort{q}{p}.$$ 
This is a typical example of linear vector field with purely imaginary eigenvalues $\lambda_{1,2}= \pm i\omega$, $i=\sqrt{-1}$. 


With a development similar to above, the couple  $q$ and $p/\omega$ can be interpreted as the real and imaginary parts of a same phasor $\mathbf{q}$ animated by  a clockwise motion of constant radius

\begin{displaymath}
\mathbf{q} = q+i\left(\frac{p}{\omega}\right) = C_0 e^{-i\omega(t-\phi_0)}, 
\end{displaymath}
where $C_0$ and $\phi_0$ are real and set by the initial condition:

\bcd
Can you see that you now have an _infinity_ of orbits which can are arbritarily far apart from each other ?  Which are they ? How can you say that this property must be specifific of non-dissipative systems ? (Class discussion sect. \ref{bcd:Ham1})
\ecd 
Now consider the slightly more realistic case of a harmonic oscillator with friction coefficient $\nu$, but for easier computation we assume a time-scale redimensionalisation such that $\omega=1$:

$$\vectort{\dot q}{\dot p} = \begin{pmatrix}  0 & 1 \\ -1 & -\nu \end{pmatrix} \vectort{q}{p}  $$

The eigenvalues are found with the characteristic equation $\lambda^2+\lambda\nu-1=0$. The eigenvalues are  $\lambda = \frac{1}{2} ( -\nu \pm \sqrt{\nu^2 - 4 })$, which are complex conjugate with negative real part for $\nu<2$. We anticipate a damped oscillation. We still use the convention $\lambda = \lambda_r \pm i \omega$, with $\lambda_r$ and $\omega$ real. 

The general solution is now:

\begin{displaymath}
\mathbf{q} = \left(q+\frac{\lambda_r}{\lambda_r^2+\omega_e^2} \right) + i\left(p\frac{\omega_e}{\lambda_r^2+\omega_e^2}\right) = C_0 e^{\lambda_r t } e^{-i(\omega_e t-\phi_0)}. 
\end{displaymath}


This _dissipative oscillator_ is thus associated with a non-hyperbolic fixed point that is a _center_, asymptotically attracting, with _spiraling_ trajectories. The phase-space interpretation is a bit less straigtforward than in the harmonic oscillator because the real and imaginary parts of the phasor are not just $q$ and $p$ but an affine transformation of them. This is the affine tranformation which was needed to give the matrix a canonical form.


### Case C: Jordan form matrix

In this case, the general solution of the trajectories is $\vec{x}(t) = (C_1 e^{\lambda t} + C_2 t e^{\lambda t}) \vec{u} +  C_2 e^{\lambda t} \vec{v}$. Again,  $\vec{u}$ and $\vec{v}$ are the columns of the matrix $T$ needed to bring $A$ into canonical form (here, for illustration, they are orthogonal, but they do not need be. 

\efigure{jordan}
\efigure{jordan05}


\bcd
Can you see that for linear fields to generate bounded trajectories within $\mathbb{R}^2$, fixed points must be either hyperbolic sinks, or centers? Sources will generate trajectories flowing to infinity.
\ecd


## Non-linear vector fields in the plane

### Topological equivalence with the linearised system around hyperbolic fixed points 

As we see now, non-linear dynamics are needed to combine hyperbolic sources with bounded behaviour, which, in the plane, will typically generate attracting orbits. We will review at a later stage the dynamics of attracting orbits, but for the moment we would like to take advantage of what we have learned about hyperbolic sources and sinks in the linear regime. The theory allows us to show that _near_ a hyperbolic fixed point, the non-linear flows behaves _like_ a linear system with the same eigenspectrum. 

To get there, we start with an example that, unusual fact, can be solved analytically. 
\begin{align*}
\dot x &= x + y^2, \\
\dot y &= -y. 
\end{align*}

The fixed point is $(x_0,y_0)=(0,0)$. Writing, more generically, the system as:
\begin{align*}
\dot x &= f(x,y), \\
\dot y &= g(x,y)
\end{align*}

we find that we can _linearise_ the system as follows (writing $x^\prime = x - x_0 = x$):

\begin{align}
\dot x &= 
     f(x_0,y_0) + 
      \left.\pd{f}{x}\right|_{(x_0,y_0)} x^\prime + 
      \left.\pd{f}{y}\right|_{(x_0,y_0)} y^\prime + 
      N_x(x,y), \\
\dot y &= 
     g(x_0,y_0) + 
      \left.\pd{g}{x}\right|_{(x_0,y_0)} x^\prime + 
      \left.\pd{g}{y}\right|_{(x_0,y_0)} y^\prime + 
      N_y(x,y), 
\end{align}

where $N_{x,y}$ include all the non-linear terms. The _tangent linear system is_, per definition: 

\begin{align*}
\dot x &= 
     f(x_0,y_0) + 
      \left.\pd{f}{x}\right|_{(x_0,y_0)} x^\prime + 
      \left.\pd{f}{y}\right|_{(x_0,y_0)} y^\prime,\\
\dot y &= 
     g(x_0,y_0) + 
      \left.\pd{g}{x}\right|_{(x_0,y_0)} x^\prime + 
      \left.\pd{g}{y}\right|_{(x_0,y_0)} y^\prime,
\end{align*}

or, written in a more compact form, and considering that, by definition of the fixed point, $f(x_0,y_0)$ and $g(x_0,y_0)=0$:

$$\vectort{\dot x}{\dot y} = \Dif_{(f,g)}(x_0,y_0)  \vectort{x}{y},$$

with $\Dif_{(f,g)}(x_0,y_0)$ the Jacobian of $(f,g)$ evaluated at the fixed point. In the specific example chosen here, 
$$\Dif_{(f,g)}(x_0,y_0) = \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix}.$$ It is already diagonal, with eigenvectors along the $x$ and $y$ axes, and eigenvalues $\lambda_1=1$ and $\lambda_2=-1$.
The phase portrait is thus fairly straightforward: 

\hfill\efigure{saddle_plane}

You identify without much difficulty the stable and unstable manifolds. 

Let us come back to our full system. The equation for $\dot y$ admits, as solution, $y(t)=C_2 e^{-t}$. Plugged into tho $\dot x$ equation, we have $\dot x= x + C_2^2 e^{-2t}$. The _homogeneous_ equation $\dot x= x$ admits, as solution, $x^H(t) = C_1 e^t$. One approach for finding a particular solution to the inhomogeneous system is to make the constant variable, that is try  $C(t)$ in lieu of $C_1$:


\begin{align*}
\dot C e^t  &= C_2^2 e^{-2t}, \\
\Leftrightarrow  C(t)  &= -\frac{1}{3} C_2^2 e^{-3t}, \\
\Leftrightarrow  x^I(t)  &= -\frac{1}{3} C_2^2 e^{-2t}.
\end{align*}

The general solution is thus $x(t)=C_1e^t - \frac{1}{3} C_2^2 e^{-2t}$. 

Starting from any point $(x_0,y_0)$ at time $t=0$, we have $C_2=y_0$, $C_1 = x_0 - \frac{1}{3}y_0^2$. 

In particular, if $y_0=0$, then $y(t)=0$ and $x(t)=x_0e^t$. Hence, along the $x$ axis, the system behaves _exactly_ as the linear system (!). The line $y=0$ is the unstable (invariant) manifold. 

Now, contrary to the linearised system, the line $x_0=0$ is _not_ an invariant manifold, as, starting  from $x_0=0$, 

$$x(t)= - \frac{1}{3} y_0^2 (  e^t + e^{-2t}).$$

However, if we are a tiny bit smarter and arrange for $C_1$ to be $0$, that is, $x_0 + \frac{1}{3}y_0^2=0$, then the system evolves as:

\begin{align*}
 x(t) &= -\frac{1}{3}y_0^2 e^{-2t}, \\
 y(t) &= y_0  e^{-t}, 
\end{align*}

on which the relationship $x_0 + \frac{1}{3}y_0^2=0$ is maintained. In other words, the curve defined by 
$x + \frac{1}{3}y^2=0$ is the stable invariant manifold. 

\efigure{non_linear_plane}


With this particular non-linear system, about which we could find the analytical solution, we observe that the invariant manifolds of the linear system are _tangent_ and have the same stability characteristics as those of the linear tangent system. This is great news, because it suggests that we can learn quite a great deal about the non-linear system from inspection of the much simpler linear system, near the fixed point. 

This is not _always_ the case, as demonstrated by the following example:

\begin{align}
\dot x &= -y + ax(x^2 + y^2), \\
\dot y &= x + ay(x^2 + y^2). 
\end{align}

Lacking time, full inspection of the system is left as an exercise, but rushing through the lessons to be learned here, one would find that the _non-linear_ system spirals downwards or upwards depending on the value of $a$ (negative or positive), while the _linear system_ is the Hamiltonian system that we have already studied above and admits circular orbits. 

So what is the trouble here? The key for establishing a qualitative equivalence between a linear and a non-linear system is the _hyperbolic_ character of the fixed points, as established by the Hartman-Grobman theorem (1959 and 1960):

\bt{Hartman-Grobman theorem}
Consider $p=(0,0)$ a _hyperbolic_ fixed point of the ordinary differential equation $\dot{\vec{x}} = \vec{f}(\vec{x})$, $\vec{x}\in\mathbb{R}^2$, 
and $\vec{f}\in\mathbf{C}^k(\mathbb{R}^2), k\geq1$. Then, there is a neighbourhood $B$ around $\vec{p}=(0,0)$ and a homeomorphism $h:B\rightarrow R^2$ with $h(0,0)=(0,0)$ such that, $\forall \vec{x}\in B$, there is an interval $I\subset\mathbb{R}$ such that:
$$h \circ \phi^t(\vec x) = \bar\phi^t \circ h(\vec x),\quad \forall t\in I, \vec{x}\in B,$$
where $\phi^t$ is the flow of $\dot{\vec{x}} = \vec{f}(\vec{x})$ and $\bar \phi^t$ is the flow of the linearised system $\dot {\vec{x}} = \Dif_{(f,g)}(\vec{p})  \vec{x}$. 
\et

It is said that the flows $\phi^t$ and $\bar \phi^t$ are _topologically conjugate_. 

The topological equivalence between linearised systems and non-linear systems around the _hyperbolic_ fixed points imply that we can predict the existence of stable and unstable invariant manifolds and their tangent directions, from inspection of the eigenvalues and eigenvectors of the Jacobian. 

We have a _sink_ if all eigenvalues are negative real parts, a _source_ if they  all have positive real parts, and a _saddle point_ if some are negative and negative, provided that none is null in which case the fixed point is no longer hyperbolic. This theory, including the Hartman-Grobman theorem, works also for $n\geq 2$. 

Specifically, we define:

\bd{Stable local manifold}
The stable local manifold around $p$ in the neighbourhood $B$ is $$S_B = \left\{ x \in B: \phi^t(x) \in B \forall t\geq 0\right\}.$$
\ed

Similarly, 

\bd{Unstable local manifold}
The unstable local manifold around $p$ in the neighbourhood $B$ is $$U_B = \left\{ x \in B: \phi^{-t}(x) \in B \forall t\geq 0\right\}.$$
\ed

Because of the way the definition is put, fixed points (even if they are saddle points or sources) belong to both the local stable and unstable manifolds. This is a bit counter-intuitive, so pay attention to this. 


### Stable-unstable manifolds theorem

Let us see one more consequence of the Hartman-Grobman theorem. 

If $p$ is a (hyperbolic) sink, then there must be a neighbourhood $B$ around $p$ such that  $S_B=B$ and $U_B=\{p\}$. Can you see this? Indeed, in this neighbourhood, the flow is topologically conjugate to that of the linearised system. We now that it is a _sink_, attracting from all directions. The  stable manifold _is_ the whole neighbourhood. But as we have just seen, $\{p\}$ must also belong to the unstable manifold. 

If $p$ is a (hyperbolic) source, then, $U_B=B$ and $S_B=\{p\}$. 

We will now formulate an important theorem, not demonstrated here, that will allow us to obtain more information about the shape of the stable and unstable manifolds around the fixed points. 

\bt{Stable and unstable manifolds theorem}
Consider $\vec{f}:\mathbb{R}^2 \rightarrow \mathbb{R}^2$, a diffeomorphism $\in \mathbf{C}^k$, $k\geq 1$, and $p=(0,0)$ a _hyperbolic_ equilibrium of the ordinary differential equation $\dot {\vec{x}} = \vec{f}(\vec{x})$, such that 

$$ \Dif \vec{f}(p)=\begin{pmatrix} \lambda_1 & 0 \\ 0 & \lambda_2 \end{pmatrix},\quad \text{with}\ \lambda_1 < 0 < \lambda_2. $$

Then, $\exists \varepsilon >0$ and $B=]-\varepsilon,\varepsilon[ \cross ]-\varepsilon,\varepsilon[$ such that:

\begin{itemize}[leftmargin=0em]
\item $S_B = \left\{ (x, s(x)) \text{with} x\in]-\varepsilon,\varepsilon[\right\}$ where $s(x)$ is $\mathbf{C}^k$ and $s^\prime(0) = 0$; 
\item $U_B = \left\{ (u(y), y) \text{with} y\in]-\varepsilon,\varepsilon[\right\}$ where $u(y)$ is $\mathbf{C}^k$ and $u^\prime(0) = 0$; 
\end{itemize}
\et 

Let us put this in plain text. If we have a hyperbolic saddle, then there is a neighbourhood where the stable manifold through the point has a functional form, tangent to the axis corresponding to the stable direction of the linearised system; and there is a  _also_ a neighbourhood where the unstable manifold has a functional form, tangent to the axis corresponding to the unstable direction of the linearised system. It results from this theorem that the stable and unstable manifolds are locally orthogonal to each other. 

The consequences are pretty wild. Indeed, suppose again that the system has been put such that the eigenvectors correspond to the $x$ and $y$ axes (as above), with $x=0$ (the $y-$axis) the unstable manifold through the origin. 

Then, we can as we have done already linearise the system: 

\begin{equation}\label{eq:manifold}
\begin{split}
\dot x &=  \lambda_1 x + N_x(x,y), \\
\dot y &=  \lambda_2 y + N_y(x,y). \\
\end{split}
\end{equation}


The non-linear terms contain second-order terms and more, so by definition $\lim_{(x,y)\rightarrow (0,0)} \frac{N_{x,y}(x,y)}{x^2+y^2} = 0$.

So, consider now $(x(t),y(t))$ an orbit of the stable manifold that passes through $x,s(x)$. It must remain on the stable manifold, and we find that $y(t)=s(x(t))$. We can re-write system \eqref{eq:manifold} as follows:

\begin{equation}\label{eq:manifoldlin}
\begin{split}
\dot x &=  \lambda_1 x +  N_x(x,s(x)), \\
\dot x s^\prime (x) &=  \lambda_2 s(x) + N_y(x,s(x)). \\
\end{split}
\end{equation}

Combining both equations to eliminate time (the $\dot x$ term), you get

\begin{equation}
s^\prime (x) (\lambda_1 x + N_x(x,s(x))) = 
\lambda_2 s(x) + N_y(x,s(x))
\end{equation}

Similarly, for the unstable form, you would get: 

\begin{equation}
(\lambda_1 u(y)x + N_x(u(y),y)) = 
u^\prime (\lambda_2 u(y) + N_y(u(y),y))
\end{equation}

We will now show how we can use these developments. Consider again the system that  we have been playing with already, but we just swap the $x$ and $y$ directions to comply with the condition $\lambda_1 < 0 < \lambda_2$:

\begin{align*}
\dot x &= - x, \\
\dot y &= y + x^2. 
\end{align*}

Thus, $N_x(x,y)=0$, $N_y(x,y)=x^2$. We had the solution, and we know that $s(x)=-\frac{1}{3}x^2$, but as we said above, it is unusual to be able to find it analytically. So suppose we don't know it. To this end, consider the differential equation for the stable manifold: 

\begin{displaymath}
s^\prime (x) (- x ) = s(x) + x^2.
\end{displaymath}

If we admit that $s$ is infinitely differentiable, and keeping in mind that its first-order derivative is null, then as a general rule we know that $s(x)=\sum_{k=2}^{\infty} s_k x^k$. Substituting in the differential equation, that makes

$$ -x \sum_{k=2}^{\infty}  k s_k x^{k-1} = x^2 + \sum_{k=2}^{\infty} s_k x^{k}.$$

Identifying terms for the different orders, one by one, we get $-2 s_2 = s_2 + 1$ and $-k s_k = s_k$ for $k\geq 3$. The only solution is $s_2=-\frac{1}{3}$ and $s_k=0$ for $k\geq 3$.

As an exercise, you could find that, for 

\begin{align*}
\dot x &= x + y^3 \\
\dot y &= -y + 2xy + x^2,
\end{align*}

we have:

\begin{align*}
u(x) &= \frac{1}{3} x^2 + \frac{1}{6}x^3 + \frac{1}{15} x^4 + \mathcal{O}(x^5) \\
s(y) &=  - \frac{1}{4} y^3 \mathcal{O}(y^5)
\end{align*}

Attention, there is a small difficulty: the roles of $x$ and $y$ are inverted compared to the theory above (in other words: $\lambda_2 < 0 < \lambda_1$. The trick is just to rename $y^\star=x$ and $x^\star=y$ and then rename back when finished. 

The graph below represents sample orbits (red) and the approximate stable and unstable manifolds (blue), the
computed stable and unstable manifolds (green), and the flow direction (arrows)

\efigure{stable}


