## Linear fields 
\label{sect:plane}

### General solution

We consider the vector field defined in $\mathbb{R}^2\rightarrow \mathbb{R}^2$, with $\vec{x} \in \mathbb{R}^2$. 
In the particular case of a linear diffeomorphism, the vector field takes a matrix form, as follows:

$$ \dot{\vec{x}}  = A \vec{x}.$$

The Jordan canonical form theorem tells us that, if $A$ is a real two by two matrix, there is a non-singular real matrix $T$ such that $A=TJT^{-1}$, and $T$ is made of the column vectors $\vec{u}$ and $\vec{v}$.  Depending on the eigenvalue and eigenvectors of $A$, $J$ will be of one of three forms:

- _Case A_: Two independent eigenvectors, real eigenvalues : $A = \begin{pmatrix} \lambda_1 & 0 \\ 0 & \lambda_2 \end{pmatrix}$;
- _Case B_: Complex eigenvalues $\alpha \pm i \beta$: $A = \begin{pmatrix} \alpha & \beta \\ -\beta & \alpha \end{pmatrix}$;
- _Case C_: A single independent eigenvector, with one single complex eigenvalue $A = \begin{pmatrix} \lambda & 0 \\ 1 & \lambda \end{pmatrix}$. 

Geometrically, $T$ is the composition of a rotation, dilation and reflection around the origin.

### Case A: Real eigenvalues and linearly independent eigenvectors : invariant manifolds and linear transient growth

The general solution to the ordinary differential equation is $$\vec{x}(t) = C_1 e^{\lambda_1 t} \vec{u} +  C_2 e^{\lambda_2 t} \vec{v},$$ where $\vec u$ and $\vec v$ are the eigenvectors, and $\lambda_1$ and $\lambda_2$ the respective eigenvalues. 

The fixed point $(0,0)$ is asymptotically attracting if it is a hyperbolic fixed point with $\lambda_{1,2} < 0$. Furthermore, for an initial condition along the eigenvector $u$, that is, $\vec{x}_0 = \alpha \vec{u}$, the particular solution is $\vec{x} = \alpha e^{\lambda_1 t} \vec{u}$. In other words, in the particular case of an initial condition along an eigenvector, the orbit is a line. 

In other words, the lines defined by $\alpha \vec{u}$ and $\beta \vec{v}$, $\alpha,\beta\in\mathbb{R}$ are invariant manifolds: if you are on the line, the flow keeps you on the line. We can already have some intuitive grasp on what is going on, and observe that the manifold might be unstable (the flow propels you to infinity), or stable (the flow asymptotically brings you to the fixed point $(0,0)$, depending on the eigenvalue. 

\includegraphics[page=15, angle=90, scale=0.7, trim={1cm 0 0 0cm}, clip]{lphys2114-figures}

In general, even if the eigenvalues are real, the orbit is _not_ a line. Consider the case of a hyperbolic sink ($\lambda_1,\lambda_2<0$). One can view that $-\lambda_1$ and $-\lambda_2$ act as the inverse of attracting time scales. For example,  $\lambda_1 \gg \lambda_2$ imply that the trajectory will be quickly attracted towards the $u-$component of the trajectory will vanish quickly, so that it will be quickly attracted towards the manifold associated with the second eigenvalue. The $\beta \vec{v}$ will act as a _slow manifold_. As it turns out, depending on the initial condition, an observer that would observe one component (say, the first component) may observe _transient growth_ before reaching the asymptotic limit $(0,0)$. 

\includegraphics[page=12, angle=90, scale=0.7, trim={2cm 0 0 0cm}, clip]{lphys2114-figures}


### Case B: Complex eigenvalues : spiral and center 

The frictionless, linear harmonic oscillator is defined by (after a suitable choice of length and time units):

$$\vectort{\dot q}{\dot p} = \begin{pmatrix}  0 & 1 \\ -1 & 0 \end{pmatrix} \vectort{q}{p}.$$ 
This is a typical example of linear vector field with purely imaginary eigenvalues $\lambda_{1,2}= \pm i$. 


The general solution is $q = C_0 e^i(t+\phi_0)$ and $p=\dot q$. 

\bcd
Can you see that you now have an _infinity_ of invariant manifolds? Which are they? This situation is quite typical of Hamiltonian (conservative flows).
\ecd 

Now consider the slightly more realistic case of a harmonic oscillator with friction coefficient $\nu$.

$$\vectort{\dot q}{\dot p} = \begin{pmatrix}  0 & 1 \\ -1 & -\nu \end{pmatrix} \vectort{q}{p}  $$

The eigenvalues are found with the characteristic equation $\lambda^2+\lambda\nu-1=0$. The eigenvalues are  $\lambda = \frac{1}{2} ( -\nu \pm \sqrt{\nu^2 - 4 })$. The weakly damped harmonic oscillator $\nu<2$ will thus be characterised by a damped oscillation, associated with two eigenvalues that are complex conjugate. 

As we see it, the _conservative_ harmonic oscillator is associated with a non-hyperbolic fixed point that is a _center_. The more general damped oscillator is associated with a hyperbolic fixed point, asymptotically attracting, that is _spiraling_. 

\includegraphics[page=16, angle=90, scale=0.7, trim={1cm 0 2cm 0cm}, clip]{lphys2114-figures}

### Case C: Jordan form matrix

In this case, the general solution of the trajectories is $\vec{x}(t) = (C_1 e^{\lambda t} + C_2 t e^{\lambda t}) \vec{u} +  C_2 t e^{\lambda t} \vec{v}$. 

\scalebox{0.8}{ \input{Figures/jordan.eepic}}
\scalebox{0.8}{ \input{Figures/jordan05.eepic}}


\bcd
Can you see that for linear fields to generate bounded trajectories within $\mathbb{R}^2$, fixed points must be either hyperbolic sinks, or centers? Sources will generate trajectories flowing to infinity.
\ecd


## Non-linear vector fields in the plane

### Topological equivalence with the linearised system around hyperbolic fixed points 

As we see now, non-linear dynamics are needed to combine hyperbolic sources with bounded behaviour, which, in the plane, will typically generate attracting orbits. We will review at a later stage the dynamics of attracting orbits, but for the moment we would like to take advantage of what we have learned about hyperbolic sources and sinks in the linear regime. The theory allows us to show that _near_ a hyperbolic fixed point, the non-linear flows behaves _like_ a linear system with the same eigenspectrum. 

To get there, we start with an example that, unusual fact, can be solved analytically. 

\begin{align*}
\dot x &= x + y^2, \\
\dot y &= -y. 
\end{align*}

The fixed point is $(x_0,y_0)=(0,0)$. Writing, more generically, the system as:

\begin{align*}
\dot x &= f(x,y), \\
\dot y &= g(x,y)
\end{align*}

we find that we can _linearise_ the system as follows (writing $x^\prime = x - x_0 = x$):

\begin{align}
\dot x &= 
     f(x_0,y_0) + 
      \left.\pd{f}{x}\right|_{(x_0,y_0)} x^\prime + 
      \left.\pd{f}{y}\right|_{(x_0,y_0)} y^\prime + 
      N_x(x,y), \\
\dot y &= 
     g(x_0,y_0) + 
      \left.\pd{g}{x}\right|_{(x_0,y_0)} x^\prime + 
      \left.\pd{g}{y}\right|_{(x_0,y_0)} y^\prime + 
      N_y(x,y), \\
\end{align}

where $N_{x,y}$ include all the non-linear terms. The _tangent linear system is_, per definition: 

\begin{align*}
\dot x &= 
     f(x_0,y_0) + 
      \left.\pd{f}{x}\right|_{(x_0,y_0)} x^\prime + 
      \left.\pd{f}{y}\right|_{(x_0,y_0)} y^\prime,\\
\dot y &= 
     g(x_0,y_0) + 
      \left.\pd{g}{x}\right|_{(x_0,y_0)} x^\prime + 
      \left.\pd{g}{y}\right|_{(x_0,y_0)} y^\prime,
\end{align*}

or, written in a more compact form, and considering that, by definition of the fixed point, $f(x_0,y_0)$ and $g(x_0,y_0)=0$:

$$\vectort{\dot x}{\dot y} = \Dif(f,g)  \vectort{x}{y},$$

with $\Dif(f,g)$ the Jacobian of $(f,g)$ evaluated at the fixed point. In the specific example chosen here, 
$$\Dif(f,g) = \begin{pmatrix} 1 & 0 \\ 0 & -1 \end{pmatrix}.$$ It is already diagonal, with eigenvectors along the $x$ and $y$ axes, and eigenvalues $\lambda_1=1$ and $\lambda_2\-1$.
The phase portrait is thus fairly straightforward: 


\includegraphics[page=13, angle=90, scale=0.7, trim={0cm 0 0 0cm}, clip]{lphys2114-figures}

You identify without much difficulty the stable and unstable manifolds. 

Let us come back to our full system. The equation for $\dot y$ admits, as solution, $y(t)=C_2 e^{-t}$. Plugged into tho $\dot x$ equation, we have $\dot x= x + C_2^2 e^{-2t}$. The _homogeneous_ equation $\dot x= x$ admits, as solution, $x^H(t) = C_1 e^t$. One approach for finding a particular solution to the inhomogeneous system is to make the constant variable, that is try  $C(t)$ in lieu of $C_1$:


\begin{align*}
\dot C e^t  &= C_2^2 e^{-2t}, \\
\Leftrightarrow  C(t)  &= -\frac{1}{3} C_2^2 e^{-3t}, \\
\Leftrightarrow  x^I(t)  &= -\frac{1}{3} C_2^2 e^{-2t}.
\end{align*}

The general solution is thus $x(t)=C_1e^t - \frac{1}{3} C_2^2 e^{-2t}$. 

Starting from any point $(x_0,y_0)$ at time $t=0$, we have $C_2=y_0$, $C_1 = x_0 - \frac{1}{3}y_0^2$. 

In particular, if $y_0=0$, then $y_t=0$ and $x(t)=x_0e^t$. Hence, along the $x$ axis, the system behaves _exactly_ as the linear system (!). The line $y=0$ is the unstable (invariant) manifold. 

Now, contrary to the linearised system, the line $x_0=0$ is _not_ an invariant manifold, as, starting  from $x_0=0$, 

$$x(t)= - \frac{1}{3} y_0^2 (  e^t + e^{-2t}).$$

However, if we are a tiny bit smarter and arrange for $C_1$ to be $0$, that is, $x_0 + \frac{1}{3}y_0^2=0$, then the system evolves as:

\begin{align*}
 x(t) &= y_0^2 e^{-2t}, \\
 y(t) &= y_0  e^{-t}, 
\end{align*}

on which the relationship $x_0 + \frac{1}{3}y_0^2=0$ is maintained. In other words, the curve defined by 
$x_0 + \frac{1}{3}y_0^2=0$ is the stable invariant manifold. 


\includegraphics[page=14, angle=90, scale=0.7, trim={0cm 0 0 0cm}, clip]{lphys2114-figures}


With this particular non-linear system, about which we could find the analytical solution, we observe that the invariant manifolds of the linear system are _tangent_ and have the same stability characteristics as those of the linear tangent system. This is great news, because it suggests that we can learn quite a great deal about the non-linear system from inspection of the much simpler linear system, near the fixed point. 

This is not _always_ the case, as demonstrated by the following example:

\begin{align}
\dot x &= -y + ax(x^2 + y^2), \\
\dot y &= x + ay(x^2 + y^2). 
\end{align}

Lacking time, full inspection of the system is left as an exercise, but rushing through the lessons to be learned here, one would find that the _non-linear_ system spirals downwards or upwards depending on the value of $a$ (negative or positive), while the _linear system_ is the Hamiltonian system that we have already studied above and admits circular orbits. 

So what is the trouble here? The key for establishing a qualitative equivalence between a linear and a non-linear system is the _hyperbolic_ character of the fixed points, as established by the Hartman-Grobman theorem (1959 and 1960):

\bt{Hartman-Grobman theorem}
Consider $p=(0,0)$ a _hyperbolic_ fixed point of the ordinary differential equation $\dot {\vec{x}} = \vec{f}(\vec{x})$, $\vec{x}\in\mathbb{R}^2$, 
and $\vec{f}\in\mathbf{C}^k(\mathbb{R}^2), k\geq1$. Then, there is a neighbourhood $B$ around $p=(0,0)$ and a homeomorphism $h:B\rightarrow R^2$ with $h(0,0)=(0,0)$ such that, $\forall \vec{x}\in B$, there is an interval $I\subset\mathbb{R}$ such that:
$$h \circ \phi^t(\vec x) = \bar\phi^t \circ h(\vec x),\quad \forall t\in I, \vec{x}\in B,$$
where $\phi^t$ is the flow of $\dot{ \vec{x}} = \vec{f}(\vec{x})$ and $\bar \phi^t$ is the flow of the linearised system $\dot {\vec{x}} = \Dif (f,g)  \vec{x}$. 
\et

It is said that the flows $\phi^t$ and $\bar \phi^t$ are _topologically conjugate_. 

The topological equivalence between linearised systems and non-linear systems around the _hyperbolic_ fixed points imply that we can predict the existence of stable and unstable invariant manifolds and their tangent directions, from inspection of the eigenvalues and eigenvectors of the Jacobian. 

We have a _sink_ if all eigenvalues are negative real parts, a _source_ if they  all have positive real parts, and a _saddle point_ if some are negative and negative, provided that none is null in which case the fixed point is no longer hyperbolic. This theory, including the Hartman-Grobman theorem, works also for $n\geq 2$. 

Specifically, we define:

\bd{Stable local manifold}
The stable local manifold around $p$ in the neighbourhood $B$ is $$S_B = \left\{ x \in B: \phi^t(x) \in B \forall t\geq 0\right\}.$$
\ed

Similarly, 

\bd{Unstable local manifold}
The unstable local manifold around $p$ in the neighbourhood $B$ is $$U_B = \left\{ x \in B: \phi^{-t}(x) \in B \forall t\geq 0\right\}.$$
\ed

Because of the way the definition is put, fixed points (even if they are saddle points or sources) belong to both the local stable and unstable manifolds. This is a bit counter-intuitive, so pay attention to this. 


### Stable-unstable manifolds theorem

Let us see one more consequence of the Hartman-Grobman theorem. 

If $p$ is a (hyperbolic) sink, then there must be a neighbourhood $B$ around $p$ such that  $S_B=B$ and $U_B=\{p\}$. Can you see this? Indeed, in this neighbourhood, the flow is topologically conjugate to that of the linearised system. We now that it is a _sink_, attracting from all directions. The  stable manifold _is_ the whole neighbourhood. But as we have just seen, $\{p\}$ must also belong to the unstable manifold. 

If $p$ is a (hyperbolic) source, then, $U_B=B$ and $S_B=\{p\}$. 

We will now formulate an important theorem, not demonstrated here, that will allow us to obtain more information about the shape of the stable and unstable manifolds around the fixed points. 

\bt{Stable and unstable manifolds theorem}
Consider $f:\mathbb{R}^2 \rightarrow \mathbb{R}^2$, a diffeomorphism $\in \mathbf{C}^k$, $k\geq 1$, and $p=(0,0)$ a _hyperbolic_ equilibrium of the ordinary differential equation $\dot x = f(x)$, such that 

$$ \Dif f(p)=\begin{pmatrix} \lambda_1 & 0 \\ 0 & \lambda_2 \end{pmatrix},\quad \text{with} \lambda_1 < 0 \lambda_2. $$

Then, $\exists \varepsilon >0$ and $B=]-\varepsilon,\varepsilon[ \cross ]-\varepsilon,\varepsilon[$ such that:

- $S_B = \left\{ (x, s(x)) \text{with} x\in]-\varepsilon,\varepsilon[\right\}$ where $s(x)$ is $\mathbb{C}^k$ and $s^\prime(0) = 0$; 
- $U_B = \left\{ (u(y), y) \text{with} x\in]-\varepsilon,\varepsilon[\right\}$ where $u(x)$ is $\mathbb{C}^k$ and $u^\prime(0) = 0$; 

\et 

Let's try to put this in plain text. If we have a hyperbolic saddle, then there is a neighbourhood where the stable manifold through the point has a functional form, tangent to the axis corresponding to the stable direction of the linearised system; and there is a  _also_ a neighbourhood where the unstable manifold has a functional form, tangent to the axis corresponding to the unstable direction of the linearised system. It results from this theorem that the stable and unstable manifolds are locally orthogonal to each other ! So this is big. 

The consequences are pretty wild. Indeed, suppose again that the system has been put such that the eigenvectors correspond to the $x$ and $y$ axes (as above), with $x=0$ (the $y-$axis) the unstable manifold through the origin. 

Then, we can as we have done already linearise the system: 

\begin{equation}\label{eq:manifold}
\begin{split}
\dot x &=  \lambda_1 x + N_x(x,y), \\
\dot y &=  \lambda_2 y + N_x(x,y). \\
\end{split}
\end{equation}


The non-linear terms contain second-order terms and more, so by definition $lim_{(x,y)\rightarrow (0,0)} \frac{N_{x,y}(x,y)}{x^2+y^2} = 0$.

So, consider now $(x(t),y(t))$ an orbit of the stable manifold that passes through $x,s(x)$. It must remain on the stable manifold, and we find that $y(t)=s(x(t))$. We can re-write system \eqref{eq:manifold} as follows:

\begin{equation}\label{eq:manifoldlin}
\begin{split}
\dot x &=  \lambda_1 x +  N_x(x,s(x)), \\
\dot x s^\prime (x) &=  \lambda_2 y + N_x(x,s(x)). \\
\end{split}
\end{equation}

Combining both equations to eliminate time (the $\dot x$ term), you get

\begin{equation}
s^\prime (x) (\lambda_1 x + N_x(x,s(x))) = 
\lambda_2 s(x) + N_y(x,s(x))
\end{equation}

Similarly, for the unstable form, you would get: 

\begin{equation}
(\lambda_1 u(y)x + N_x(u(y),y)) = 
u^\prime (\lambda_2 u(y) + N_y(u(y),y))
\end{equation}

We will now show how we can use these developments. Consider again the system that  we have been playing with already, but we just swap the $x$ and $y$ directions to comply with the condition $\lambda_1 < 0 < \lambda_2$:

\begin{align*}
\dot x &= - x, \\
\dot y &= y + x^2. 
\end{align*}

Thus, $N_x(x,y)=0$, $N_y(x,y)=x^2$. We had the solution, and we know that $s(x)=-\frac{1}{3}x^2$, but as we said above, it is unusual to be able to find it analytically. So suppose we don't know it. To this end, consider the differential equation for the stable manifold: 

\begin{displaymath}
s^\prime (x) (- x ) = s(x) + x^2.
\end{displaymath}

If we admit that $s$ is infinitely differentiable, and keeping in mind that its first-order derivative is null, then as a general rule we know that $s(x)=\sum_{k=2}^{\infty} s_k x^k$. Substituting in the differential equation, that makes

$$ -x \sum_{k=2}^{\infty}  s_k x^{k-1} = x^2 + \sum_{k=2}^{\infty} -k s_k x^{k}.$$

Identifying terms for the different orders, one by one, we get $-2 s_2 = s_2 + 1$ and $-k s_k = s_k$ for $k\geq 3$. The only solution is $s_2=-\frac{1}{3}$ and $s_k=0$ for $k\geq 3$.

As an exercise, you could find that, for 

\begin{align*}
\dot x &= x + y^3 \\
\dot y &= -y + 2xy + x^2,
\end{align*}

we have:

\begin{align*}
u(x) &= \frac{1}{3} x^2 + \frac{1}{6}x^3 + \frac{1}{15} x^4 + \mathcal{O}(x^5) \\
s(y) &=  - \frac{1}{4} y^3 \mathcal{O}(y^5)
\end{align*}

Attention, there is a small difficulty: the roles of $x$ and $y$ are inverted compared to the theory above (in other words: $\lambda_2 < 0 < \lambda_1$. The trick is just to rename $y^\star=x$ and $x^\star=y$ and then rename back when finished. 

The graph below represents sample orbits (red) and the approximate stable and unstable manifolds (blue), the
computed stable and unstable manifolds (green), and the flow direction (arrows)

\input{Figures/stable.eepic}

## Lyapunov functions

(cf. Wiggins chap 2)

The method of Lyapunov functions can be used to determine the stability of fixed points when the information obtained from the linearisation is inconclusive (e.g. non-hyperbolic fixed points). As noted by Wiggins, the Lyapunov theory is a large area, and we examine here a very small part of it. Furthermore, while it is presented here in a chapter about vector fields in $\mathbb{R}^2$, it is in fact valid in any dimension, but so much easier to visualise on the plane. 

The basic idea is to find, in a neighbourhood of the fixed point, a function of the state that is positive, zero at the fixed point, and known to decay strictly monotonously over time. In which case, quite intuitively, the fixed point is asymptotically stable. 

More specifically, consider the following vector field: 

\begin{align*}
\dot x &= f(x,y) \\
\dot y &= g(x,y),\quad (x,y)\in\mathbb{R}^2,
\end{align*}

with fixed point $(x_f,y_f)$. Let $V(x,y)$ a scalar-valued function on $\mathbb{R}^2$ that is at least $\mathbf{C}^1$, such that $V(x_f,y_f)=0$.


\includegraphics[page=19, angle=90, scale=0.7, trim={1cm 0 0 0cm}, clip]{lphys2114-figures}

Suppose also that the locus of points satisfying $V(x,y)=C$ (constant) forms closed curves for different values of $C$ encircling $(x_f,y_f)$. Now, recall that the gradient of $V$, $\nabla V$, is a vector perpendicular to the tangent of the curves, pointing to the direction of increasing $V$. If this vector is always pointing outwards (decreasing values of $C$ as we get closer to $(x_f,y_f)$, then we get $\nabla V(x,y)\cdot (\dot x, \dot y) \leq 0$. Now we can state the general theorem

\bt{Existence of Lyapunov function implies stabilitiy}
In the conditions stated above, with $V(x_f,y_f) = 0$ and $V(x_f,y_f) > 0$ if $(x,y)\neq(x_f,y_f)$, if there exists a neighbourhood $U$ around $(x_f,y_f)$ such that:
- $\dot V(x) \leq 0$ in  $U\\{(x_f,y_f)}$ : $(x_f,y_f)$ is stable
- $\dot V(x) < 0$ in  $U\\{(x_f,y_f)}$ : $(x_f,y_f)$ is _asymptotically_ stable

\et 

Although quite intuitive, the proof is not quite straightforward and will only be discussed during the lecture time permitting. It is available in @Wiggins03aa, p. 24. 

More insightful for the physicist is the physical meaning attached to $V$. In a conservative (Hamiltonian system), the Hamiltonian would actually satisfy the definition of a Lyapunov function, although this is a limit case, where $\dot V(x)=0$. In a thermodynamic system, then the Free Energy (at constant temperature) or the Gibbs free energy (at constant pressure) work as Lyapunov functions. In the simpler case of a near Hamiltonian system (e.g. pendulum with friction), then the potential + kinetic energy $V$ satisfy the definition of a Lyapunov function near the fixed point. 


So, in principle we have a good method for proving the stability of a fixed point; in practice, finding $V$ is not always as straightforward as in the cases above. There is no miracle receipt. 

Again, the evolution of the Lyapunov function must be (strictly) monotonous in a neighbourhood of the fixed point. The latter may be arbitrarily small to satisfy the mathematical definition of an asymptotically stable fixed point, though of course, for physical significance, we might want a large neighbourhood !

Indeed, as we see it, a contour $C$ within which $\dot V(x) \leq 0$ will effectively act as a _trapping region_, that is defined as a region that contains all its future states.

\bd{Trapping region}
A trapping region $U$ relative to a diffeomorphism is a region such that $phi^t(U) \subset U\ \forall t >0$. 
\ed

An attracting set is the asymptotic limit of the sequence of contractions of the trapping regions, which is technically defined as follows:

\bd{Attracting set}
An attracting set exists if it can be defined as $\bigcap\limits_{t>0}^\infty \phi^t(U)$.
\ed

Conversely, the _basin_ of attraction relative to the attracting set $A$ is the set of initial conditions that eventually falls into it:

\bd{Basin of attraction}
The basing of attraction (or _domain_) of an attracting set $A$ is  $\bigcup\limits_{t\leq 0}^\infty \phi^t(U)$, where $U$ is an open neighbourhood acting as a trapping region leading to $A$. 
\ed

Below is an example of basins of attractions of two sinks. The sinks act as two individual _attracting sets_. 

\includegraphics[page=20, angle=90, scale=0.7, trim={1cm 0 0 0cm}, clip]{lphys2114-figures}


